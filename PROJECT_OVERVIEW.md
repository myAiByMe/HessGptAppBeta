# ğŸ“± HessGPT Mobile - Vue d'ensemble du projet

## ğŸ¯ Objectif

Application mobile Android native permettant d'exÃ©cuter votre modÃ¨le de langage HessGPT (0.5B paramÃ¨tres) **100% offline** sur smartphone, sans connexion internet requise.

## ğŸ—ï¸ Architecture Technique

### Stack Technologique

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Interface Utilisateur          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  ChatActivity (Kotlin)          â”‚  â”‚
â”‚   â”‚  - RecyclerView pour messages   â”‚  â”‚
â”‚   â”‚  - Material Design 3            â”‚  â”‚
â”‚   â”‚  - Streaming en temps rÃ©el      â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚        Couche de Gestion ML             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  ModelManager (Kotlin)          â”‚  â”‚
â”‚   â”‚  - Chargement du modÃ¨le         â”‚  â”‚
â”‚   â”‚  - InfÃ©rence PyTorch Mobile     â”‚  â”‚
â”‚   â”‚  - GÃ©nÃ©ration autoregressive    â”‚  â”‚
â”‚   â”‚  - Top-K/Top-P sampling         â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  Tokenizer (Kotlin)             â”‚  â”‚
â”‚   â”‚  - Encode texte â†’ IDs           â”‚  â”‚
â”‚   â”‚  - Decode IDs â†’ texte           â”‚  â”‚
â”‚   â”‚  - Support BPE                  â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         PyTorch Mobile Runtime          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  TorchScript (.ptl)             â”‚  â”‚
â”‚   â”‚  - ModÃ¨le HessGPT optimisÃ©      â”‚  â”‚
â”‚   â”‚  - Quantification INT8          â”‚  â”‚
â”‚   â”‚  - Architecture GPT + RoPE      â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Composants Principaux

#### 1. **ModelManager.kt**
- Charge le modÃ¨le TorchScript depuis les assets
- GÃ¨re le cycle de vie du modÃ¨le (load/release)
- ImplÃ©mente la gÃ©nÃ©ration token par token
- Applique les stratÃ©gies de sampling (temperature, top-k, top-p)

#### 2. **Tokenizer.kt**
- Encode le texte en IDs de tokens
- DÃ©code les IDs en texte lisible
- Supporte BPE (Byte Pair Encoding)
- GÃ¨re les tokens spÃ©ciaux (EOS, BOS, PAD)

#### 3. **ChatActivity.kt**
- Interface utilisateur du chat
- Streaming des tokens en temps rÃ©el
- Gestion de l'historique des messages
- Affichage des performances

#### 4. **PerformanceMonitor.kt**
- Mesure la latence d'infÃ©rence
- Calcule le dÃ©bit (tokens/seconde)
- Monitore le temps jusqu'au premier token

## ğŸ“Š Flux de DonnÃ©es

```
User Input
    â†“
[Tokenizer] â†’ IDs: [123, 456, 789]
    â†“
[ModelManager] â†’ Forward pass
    â†“
[PyTorch Mobile] â†’ Logits: [50257 dimensions]
    â†“
[Sampling] â†’ Next Token ID: 234
    â†“
[Tokenizer] â†’ Decoded Token: "bonjour"
    â†“
UI Update (streaming)
```

## ğŸ”§ Pipeline d'Export

### 1. EntraÃ®nement (votre cÃ´tÃ©)
```python
# Dans HessGpt_RoPE/
python PreTrain.py --config config.yaml
# â†’ GÃ©nÃ¨re: checkpoint.pt
```

### 2. Export vers TorchScript
```python
# Dans HessGptMobileApp/python/
python export_model.py --checkpoint checkpoint.pt
# â†’ GÃ©nÃ¨re: model.ptl
```

### 3. Quantification (optionnel)
```python
python quantize_model.py --input model.ptl
# â†’ GÃ©nÃ¨re: model_quantized.ptl (rÃ©duction ~75%)
```

### 4. DÃ©ploiement Android
```bash
# Copier dans assets/
cp model.ptl app/src/main/assets/
cp tokenizer.json app/src/main/assets/

# Build Android
./gradlew assembleDebug
```

## ğŸ’¾ Gestion de la MÃ©moire

### Occupation MÃ©moire EstimÃ©e

Pour un modÃ¨le de **0.5B paramÃ¨tres**:

| Composant | FP32 | INT8 (quantifiÃ©) |
|-----------|------|------------------|
| ModÃ¨le | ~2 GB | ~500 MB |
| KV-Cache (512 tokens) | ~100 MB | ~25 MB |
| Activations | ~50 MB | ~50 MB |
| **Total** | **~2.15 GB** | **~575 MB** |

### Optimisations MÃ©moire

1. **Quantification INT8**: RÃ©duit les poids de FP32 â†’ INT8
2. **Limitation de sÃ©quence**: max_seq_len = 512 au lieu de 2048
3. **Batch size = 1**: Pas de batching, un exemple Ã  la fois
4. **Pas de gradients**: `requires_grad = False` partout

## âš¡ Performances Attendues

### Sur Snapdragon 720G (mid-range 2020)

| MÃ©trique | Valeur |
|----------|--------|
| Latence 1er token | 800-1200 ms |
| DÃ©bit | 3-5 tokens/sec |
| MÃ©moire utilisÃ©e | ~1.5 GB RAM |
| Taille APK | ~550 MB |

### Sur Snapdragon 8 Gen 2 (flagship 2023)

| MÃ©trique | Valeur |
|----------|--------|
| Latence 1er token | 200-400 ms |
| DÃ©bit | 12-18 tokens/sec |
| MÃ©moire utilisÃ©e | ~1.2 GB RAM |
| Taille APK | ~550 MB |

## ğŸ” SÃ©curitÃ© et ConfidentialitÃ©

### Avantages du On-Device ML

âœ… **ConfidentialitÃ© totale**: Aucune donnÃ©e n'est envoyÃ©e Ã  un serveur
âœ… **Pas de connexion requise**: Fonctionne en mode avion
âœ… **Latence rÃ©duite**: Pas de roundtrip rÃ©seau
âœ… **Gratuit**: Pas de coÃ»ts d'API

### ConsidÃ©rations

âš ï¸ **Taille de l'app**: ~500MB, nÃ©cessite stockage suffisant
âš ï¸ **Batterie**: L'infÃ©rence consomme de l'Ã©nergie
âš ï¸ **Performances variables**: DÃ©pend du hardware de l'appareil

## ğŸ“ˆ Ã‰volutions Futures

### Version 1.1 (Court terme)
- [ ] KV-Cache persistant pour accÃ©lÃ©rer la gÃ©nÃ©ration
- [ ] Support du mode sombre
- [ ] Sauvegarde des conversations (Room Database)
- [ ] Partage des messages

### Version 1.2 (Moyen terme)
- [ ] Fine-tuning on-device avec LoRA
- [ ] Support de plusieurs modÃ¨les
- [ ] SynthÃ¨se vocale des rÃ©ponses
- [ ] Reconnaissance vocale pour l'input

### Version 2.0 (Long terme)
- [ ] ModÃ¨les multimodaux (texte + images)
- [ ] GÃ©nÃ©ration d'images on-device
- [ ] Support iOS avec Core ML
- [ ] Apprentissage fÃ©dÃ©rÃ©

## ğŸ“ Apprentissages ClÃ©s

### PyTorch Mobile
- Conversion TorchScript: `torch.jit.trace()` vs `torch.jit.script()`
- Optimisation: `optimize_for_inference()` critique
- Quantification: Dynamic quantization pour LLMs

### Android
- Assets: Copie au runtime dans le cache pour accÃ¨s PyTorch
- Threads: InfÃ©rence sur thread sÃ©parÃ© (Coroutines)
- MÃ©moire: LibÃ©ration explicite avec `module.destroy()`

### Performance
- Top-K/Top-P sampling: Ã‰quilibre diversitÃ©/qualitÃ©
- Streaming: Callback pour affichage progressif
- Monitoring: Mesure prÃ©cise avec System.currentTimeMillis()

## ğŸ“š Ressources

### Documentation
- [PyTorch Mobile Docs](https://pytorch.org/mobile/home/)
- [Android ML Kit](https://developers.google.com/ml-kit)
- [TorchScript Guide](https://pytorch.org/docs/stable/jit.html)

### Papiers de Recherche
- **RoPE**: "RoFormer: Enhanced Transformer with Rotary Position Embedding"
- **Quantization**: "Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference"
- **On-Device LLMs**: "MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use Cases"

### Repos Similaires
- [GPT-2 Android](https://github.com/huggingface/tflite-android-transformers)
- [BLOOM Mobile](https://github.com/ml-opensource/bloom-mobile)
- [LLaMA.cpp](https://github.com/ggerganov/llama.cpp) (inspiration C++)

## ğŸ¤ Contributions

Ce projet est un template de base. AmÃ©liorations bienvenues:
- Optimisations de performance
- Support de plus de tokenizers
- UI/UX amÃ©liorÃ©e
- Tests unitaires
- CI/CD

## ğŸ“„ Licence

Adaptez selon votre projet HessGPT.

---

**CrÃ©Ã© avec â¤ï¸ pour faire tourner des LLMs partout, mÃªme offline!**
